# HashMap基于基于JDK1.8
采用数组+链表红黑树实现；链表长度>8 & 数组大小>=64则会转换成红黑树，红黑树节点个数<6则转换成链表。这样设置边界是为了避免链表和红黑树之间频繁转换。

数据插入原理：
  - 判断数组是否为空，如果为空初始化数组
  - 计算存储位置，首先计算关键词的hash值，然后（n-1）& hash计算小标index
  - 查看数组是否存在值，没有数据就直接放入
  - 存在数据时，先判断key是否相等，相等就用新的value替换
  - 不相等时，先判断当前节点是否为树形=型节点，如果是树型节点，创造树型节点插入红黑树中
  - 如果不是树型节点，创建普通Node加入链表中。再判断链表长度是否大于8并且数组长度大于64，大于的话讲链表转换为红黑树
  - 插入完成之后判断当前节点数是否大于阈值，如果大于则开始扩容为原数组额2倍

HashMap初始化
  - 采用new HashMap()方式初始化，不传值则默认大小为16，负载因子0.75
  - 如果传入初始大小k，那么初始化大小则为大于k的2的最小整数次方。例如传入20，那么大小则为32

HashMap哈希函数设计
  - 首先计算key的hashcode，获得一个32位的int值
  - 然后将hashcode的高16位和低16位进行异或操作
  
这个操作叫做扰动函数，尽可能的降低了hash碰撞，让其更加分散。异或操作采用位运算，算法更加高效，降低开销。

int类型的取值范围在-21亿到+21亿之间，映射空间很大，只要哈希函数映射比较均匀很难出现碰撞，但是40亿长度的数组内存放不下，初始化才16.所以用之前对数组长度进行取模运算，得到余数才能用来访问数组下标

模运算时，把散列值和数组长度-1做一个“与”操作，采用位运算比取余%运算更快。HashMap的数组长度取2的整数幂，幂值正好是数组长度-1，相当于一个“低位掩码”。“与”操作的结果就是散列值得高位全部归零，只保留低位值，用来做数组下标访问。这样操作，即使散列值分布的在松散，取最后几位也会使碰撞变得很严重。这是采用扰动函数来解决这一问题。右移16位，自己的高半区和低半区做异或，混合可高位和低位，加大低位的随机性，混合后的低位掺杂了高位的部分特征，变相的保留了高位信息。

  - 链表的插入方式为尾插法
  - 扩容时在数组位置不变或者为索引+旧容量大小
  - 头插法在多线程环境下会产生环，尾插法在多线程环境下会有数据覆盖问题

线程安全的Map
  - HashTable：直接在操作方法上加synchronized关键字，锁住整个数组，粒度比较大
  - Collections.synchronizedMap()：通过传入Map封装出一个synchronizedMap对象，内部定义一个对象锁，方法内通过对象锁实现
  - ConcurrentHashMap：使用分段锁，降低锁粒度，让并发度大大提高
  
HashMap内部节点是无序的，根据hash值随机插入，有序的Map
  - LinkedHashMap：单链表有头尾节点，可以实现插入和访问的顺序
  - TreeMap：按照可以的自然顺序或者Comparator的顺序进行排序，内部通过红黑树实现


# ConcurrentHashMap基于JDK1.8

采用table数组+单项链表+红黑树结构实现;采用数组元素作为锁，来实现对每一行数据进行加锁，减少并发冲突的概率

HashEntry在1.8中统称为Node，当Node的数量超过8个时，会自动从链表转换为TreeNode红黑树，查询时时间复杂度由O(n)变为O(log(n))

使用内置锁synchronized代替重入锁ReentrantLock

- 因为粒度降低了，两种方式性能相差不多，在粗粒度加锁中ReentrantLock可通过Condition来控制各个低粒度的边界，更加灵活。而在低粒度中，Condition没有优势
- 基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然
- 大数据操作下，synchronized的开销会更小，虽然不是瓶颈。
