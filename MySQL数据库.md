# 概述

# 字段设计

  - 尽量使用整型便是字符串
     - 存储IP，使用INET_ATON(str)和INET_NTOA(number)来进行转化
     - MySQL内部的枚举类型（单选）和集合类型（多选）因为维护成本较高因此不常使用，通过关联表的方式来代替enum

  - 定长和非定长数据类型的选择
     - decimal不会损失精度，存储空间会随数据的增大而增大。double占用固定空间，较大数的存储会损失精度。非定长的还有varchar、text
     - 金额：对数据的精度要求较高，小数的运算和存储存在精度问题（不能将所有小数转换成二进制）
     - 定点数decimal：price decimal(8,2)有2位小数的定点数，定点数支持很大的数（甚至是超过int,bigint存储范围的数）
     - 小单位大数额避免出现小数
     - 字符串存储:定长char，非定长varchar、text（上限65535，其中varchar还会消耗1-3字节记录长度，而text使用额外空间记录长度）
  
  - 尽可能选择小的数据类型和指定短的长度

  - 尽可能使用not null
    - 非null字段的处理要比null字段的处理高效些！且不需要判断是否为null。
    - null在MySQL中，不好处理，存储需要额外空间，运算也需要特殊的运算符。如select null = null和select null <> null（<>为不等号）有着同样的结果，只能通过is null和is not null来判断字段是否为null。
    - MySQL中每条记录都需要额外的存储空间，表示每个字段是否为null。因此通常使用特殊的数据进行占位，比如int not null default 0、string not null default ‘’
  
  - 字段注释要完整，见名知意
  
  - 单表字段不宜过多
    > 二三十个就极限了
  
  - 可以预留字段
    > 在使用以上原则之前首先要满足业务需求
  
  - 关联表的设计
    > 外键foreign key只能实现一对一或一对多的映射
    - 一对多：
      > 使用外键
    - 多对多：
      > 单独创建一张表将多对多拆分成两个一对多
    - 一对一：
      > 通常使用相同的主键或者增加一个外键字段
  
  - 范式 Normal Format
    - 第一范式1NF：字段原子性
      > 字段不可再分割，关系型数据库，默认满足第一范式，注意比较容易出错的一点，在一对多的设计中使用逗号分隔多个外键，这种方法虽然存储方便，但不利于维护和索引
    - 第二范式：消除对主键的部分依赖
      > 在表中加上一个与业务逻辑无关的字段作为主键
    - 第三范式：消除对主键的传递依赖
      > 传递依赖即，B字段依赖于A，C字段又依赖于B。因此需要根据独立数据独立将此表拆分为两张表，通过外键关联，减少数据冗余。
  
  
# 存储引擎选择
  - 存储引擎选择
    > 早期问题：如何选择MyISAM和Innodb？现在不存在这个问题了，Innodb不断完善，从各个方面赶超MyISAM，也是MySQL默认使用的。
  
  - 功能差异
  
| 类型 | 支持 | 备注 |
| --- | --- | --- |
| InnoDB | 默认 | **支持事务, 行级锁, 外键** |
| MyISAM | 是 | **表级锁** |

  - 存储差异
  
|                                                              | MyISAM                                            | Innodb                                   |
| ------------------------------------------------------------ | ------------------------------------------------- | ---------------------------------------- |
| 文件格式                                                     | 数据和索引是分别存储的，数据`.MYD`，索引`.MYI`    | 数据和索引是集中存储的，`.ibd`           |
| 文件能否移动                                                 | 能，一张表就对应`.frm`、`MYD`、`MYI`3个文件       | 否，因为关联的还有`data`下的其它文件     |
| 记录存储顺序                                                 | 按记录插入顺序保存                                | 按主键大小有序插入                       |
| 空间碎片（删除记录并`flush table 表名`之后，表文件大小不变） | 产生。定时整理：使用命令`optimize table 表名`实现 | 不产生                                   |
| 事务                                                         | 不支持                                            | 支持                                     |
| 外键                                                         | 不支持                                            | 支持                                     |
| 锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的） | 表级锁定                                          | 行级锁定、表级锁定，锁定力度小并发能力高 |

    - 锁扩展 
      > 表级锁（`table-level lock`）：`lock tables <table_name1>,<table_name2>... read/write`，`unlock tables <table_name1>,<table_name2>...`。其中`read`是共享锁，一旦锁定任何客户端都不可读；`write`是独占/写锁，只有加锁的客户端可读可写，其他客户端既不可读也不可写。锁定的是一张表或几张表。
      > 行级锁（`row-level lock`）：锁定的是一行或几行记录。共享锁：`select * from <table_name> where <条件> LOCK IN SHARE MODE;`，对查询的记录增加共享锁；`select * from <table_name> where <条件> FOR UPDATE;`，对查询的记录增加排他锁。这里**值得注意**的是：`innodb`的行锁，其实是一个子范围锁，依据条件锁定部分范围，而不是就映射到具体的行上，因此还有一个学名：间隙锁。比如`select * from stu where id < 20 LOCK IN SHARE MODE`会锁定`id`在`20`左右以下的范围，你可能无法插入`id`为`18`或`22`的一条新纪录。
  
  - 选择依据
    - 如果没有特别的需求，使用默认的Innodb即可。
      > MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。
      > Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键保证数据完整性。比如OA自动化办公系统。
# 事务

事务的四大特征
  
  - 原子性：事务是最小的单位，不可再分
  - 一致性：事务要求所有的DML语句操作的时候，必须保证同时成功或者失败
  - 隔离性：事物之间具有隔离性
  - 持久性：是事务的保证，事务终结的标志（内存的数据持久到硬盘文件中）
  
  事务的隔离级别
  
  - 读未提交：隔离级别最低，可以读到其他事务未提交的数据“脏数据”。比如修改数据失败，数据回滚，读到的是修改失败的数据，而不是回滚后的数据
  - 读已提交：只能读其他事务已提交的数据，可能导致“不可重复读”
  - 可重复读：读取不到其他事务提交的数据，会导致幻读。幻读即读到的数据不是最新的数据。
  - 串行化：事务之间需要排队等待，不能保证并发，吞吐量很低。


# 索引

  > 关键字与数据的映射关系称为索引（==包含关键字和对应的记录在磁盘中的地址==）。关键字是从数据当中提取的用于标识、检索数据的特定内容。
  
  - 索引检索为什么快
  
    > 关键字现对于数据本身数据量小
    > 关键字是有序的，可以二分法快速查找
  
  - MySQL中的索引类型
  
    - 普通索引（key）：对关键字没有限制
    - 唯一索引（unique key）：要求记录提供的关键字不能重复
    - 主键索引（primary key）：要求关键字唯一且不为null
    - 全文索引（fulltext key）
  
  - 索引语法管理
  
    - 查看索引
    
    - 创建索引
      - 创建表之后建立索引
      - 创建表时指定索引
      
    - 删除索引
      > 删除主键索引时，如果主键自增长，需要先取消自增长再删除索引
  
  - 执行计划Explain
    > 使用explain关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的，分析你的查询语句或是表结构的性能瓶颈。
  
  - 索引使用场景
  
    - where
    
    - order by
      > 没有索引时，查询出的数据会先外部排序（从硬盘读到内存使用内部排序，最后合并排序结果），这个操作影响性能。因为索引是有序的，逐条取出即可。
   
    - join
      > 对join语句匹配关系（on）涉及的字段建立索引能够提高效率
    
    - 索引覆盖
      > 如果要查询的字段都简历索引，那么搜索引擎会直接在索引表中查询而不会访问原始数据
  
  - 语法细节
    > 在满足索引使用的场景下（where/order by/join on或索引覆盖），索引也不一定被使用
  
    - 字段要独立出现
    - like查询，不能以通配符开头
    - 复合索引只对第一个字段有效
    - or，两边条件都有索引可用
    - 状态值，不容易使用到索引
  
  - 如何创建索引
    - 建立基础索引：在where、order by、join字段上建立索引
    - 优化，组合索引：基于业务逻辑
      - 如果条件经常性出现在一起，那么可以考虑将多字段索引升级为复合索引
      - 如果通过增加个别字段的索引，就可以出现索引覆盖，那么可以考虑为该字段建立索引
      - 查询时，不常用到的索引，应该删除掉
  
  - 前缀索引
    语法：index(field(10))，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引
    前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。
    实操的难度：在于前缀截取的长度
      > 我们可以利用select count(*)/count(distinct left(password,prefixLen));，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）
  
  - 索引的存储结构
    - BTree
      btree（多路平衡查找树）是一种广泛应用于磁盘上实现索引功能的一种数据结构，也是大多数数据库索引表的实现。
        > BTree的一个node可以存储多个关键字，node的大小取决于计算机的文件系统，因此我们可以通过减小索引字段的长度使结点存储更多的关键字。如果node中的关键字已满，那么可以通过每个关键字之间的子节点指针来拓展索引表，但是不能破坏结构的有序性
        > 与二叉搜索树的思想是一样的，只不过二叉搜索树的查找效率是log(2,N)（以2为底N的对数），而BTree的查找效率是log(x,N)（其中x为node的关键字数量，可以达到1000以上）,从log(1000+,N)可以看出，少量的磁盘读取即可做到大量数据的遍历，这也是btree的设计目的
    
    - B+Tree聚簇结构
      > 聚簇结构（也是在BTree上升级改造的）中，关键字和记录是存放在一起的。
      > 在MySQL中，仅仅只有Innodb的==主键索引为聚簇结构==，其它的索引包括Innodb的非主键索引都是典型的BTree结构。
    
    - 哈希索引
      > 在索引被载入内存时，使用哈希结构来存储。

# 查询缓存
  
  - 在配置文件中开起缓存
    - windows上是my.ini，linux上是my.cnf。
    -在[mysqld]段中配置query_cache_type：
      - 0：不开启
      - 1：开启，默认缓存所有，需要在SQL语句中增加select sql-no-cache提示来放弃缓存
      - 2：开启，默认都不缓存，需要在SQL语句中增加select sql-cache来主动缓存（常用）
    
  - 在客户端设置缓存大小
    > 通过配置项query_cache_size来设置：
  
  - 将查询结果缓存
    、、、
    select sql_cache * from user;
    、、、
  
  - 重置缓存
    、、、
    reset query cache;
    、、、
    
  - 缓存失效问题
    > 当数据表改动时，基于该数据表的任何缓存都会被删除。（表层面的管理，不是记录层面的管理，因此失效率较高）
  
  - 注意事项
    1.应用程序，不应该关心query cache的使用情况。可以尝试使用，但不能由query cache决定业务逻辑，因为query cache由DBA来管理。
    2.缓存是以SQL语句为key存储的，因此即使SQL语句功能相同，但如果多了一个空格或者大小写有差异都会导致匹配不到缓存。


# 分区

  > 一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。
  >
  > 当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率。
  >
  > 最常见的分区方案是按id分区，如下将id的哈希值对10取模将数据均匀分散到10个.ibd存储文件中

  - MySQL提供的分区方法
    > 分区依据的字段必须是主键的一部分,分区是为了快速定位数据，因此该字段的搜索频次较高应作为强检索字段
    
    - hash(field)：相同的输入得到相同的输出。输出的结果跟输入是否具有规律无关，仅适用于整型字段
    - key(field)：和hash(field)的性质一样，只不过key是处理字符串的，比hash()多了一步从字符串中计算出一个整型在做取模操作。
    - range算法：是一种条件分区算法，按照数据大小范围分区（将数据使用某种条件，分散到不同的分区中）。
      > 条件运算符只能使用less than，这意味着较小的范围要放在前面
     - list算法：也是一种条件分区，按照列表值分区（in (值列表)）
    
  - 分区管理语法
  
    - range/list
      - 新增分区
      - 删除分区
    - key/hash
      - 新增分区
      - 销毁分区
        > key/hash分区的管理不会删除数据，但是每一次调整（新增或销毁分区）都会将所有的数据重写分配到新的分区上。==效率极低==，最好在设计阶段就考虑好分区策略
    
  - 分区的使用
  当数据表中的数据量很大时，分区带来的效率提升才会显现出来。
  带来的效率提升才会比较明显。因此，分区字段的选择很重要，并且业务逻辑要尽可能地根据分区字段做相应调整（尽量使用分区字段作为查询条件）。

# 水平分割和垂直分割

  > 水平分割：通过建立结构相同的几张表分别存储数据
  >
  > 垂直分割：将经常一起使用的字段放在一个单独的表中，分割后的表记录之间是一一对应关系。
  
  - 分表原因
    - 为数据库减压
    - 分区算法局限
    - 数据库支持不完善
  
  - id重复的解决方案
    - 借用第三方应用的id自增器
    - 单独建一张只包含id的表，每次自增该字段作为数据记录的id

# 集群

  - 安装和主从配置
    - 环境
    - 安装和配置
    - 配置主从节点
    - 测试
    
  - 读写分离
    > 读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。因为主从复制要求slave不能写只能读（如果对slave执行写操作，那么show slave status将会呈现Slave_SQL_Running=NO，此时你需要按照前面提到的手动同步一下slave）。
    
    - 定义两种连接
    - 使用Spring SOP
    
  - 负载均衡
    - 轮训
    - 加权轮询：按照处理能力来加权
    - 负载分配：依据当前的空闲状态
    
  - 高可用
  
# 典型SQL

  - 线上DDL
    DDL(Database Definition Language)是指数据库表结构的定义（create table）和维护（alter table）的语言
    优化技巧是采用的维护表结构的DDL（比如增加一列，或者增加一个索引），是==copy==策略。思路：创建一个满足新结构的新表，将旧表数据==逐条==导入（复制）到新表中，以保证==一次性锁定的内容少==（锁定的是正在导入的数据），同时旧表上可以执行其他任务。导入的过程中，将对旧表的所有操作以日志的形式记录下来，导入完毕后，将更新日志在新表上再执行一遍（确保一致性）。最后，新表替换旧表（在应用程序中完成，或者是数据库的rename，视图完成）。
    
  - 数据库导入语句
    - 导入时先禁用索引和约束
    - 数据库如果使用的引擎是Innodb，那么它默认会给每条写指令加上事务（这也会消耗一定的时间），因此建议先手动开启事务，再执行一定量的批量导入，最后手动提交事务
    - 如果批量导入的SQL指令格式相同只是数据不同，那么你应该先prepare预编译一下，这样也能节省很多重复编译的时间
     
  - limit offset rows
    尽量保证不要出现大的offset，比如limit 10000,10相当于对已查询出来的行数弃掉前10000行后再取10行，完全可以加一些条件过滤一下（完成筛选），而不应该使用limit跳过已查询到的数据。这是一个==offset做无用功==的问题。对应实际工程中，要避免出现大页码的情况，尽量引导用户做条件过滤
    
  - select*要少用
    即尽量选择自己需要的字段select，但这个影响不是很大，因为网络传输多了几十上百字节也没多少延时，并且现在流行的ORM框架都是用的select *，只是我们在设计表的时候注意将大数据量的字段分离
    
  - order by rand（）不要用
    它的逻辑就是随机排序（为每条数据生成一个随机数，然后根据随机数大小进行排序）。如select * from student order by rand() limit 5的执行效率就很低，因为它为表中的每条数据都生成随机数并进行排序，而我们只要前5条。
  解决思路：在应用程序中，将随机的主键生成好，去数据库中利用主键检索
  
  - 单表和多表查询
    多表查询：join、子查询都是涉及到多表的查询。如果你使用explain分析执行计划你会发现多表查询也是一个表一个表的处理，最后合并结果。因此可以说单表查询将计算压力放在了应用程序上，而多表查询将计算压力放在了数据库上
  
  - count（*）
    在MyISAM存储引擎中，会自动记录表的行数，因此使用count(*)能够快速返回。而Innodb内部没有这样一个计数器，需要我们手动统计记录数量，解决思路就是单独使用一张表
  
  - limit 1
    如果可以确定仅仅检索一条，建议加上limit 1，其实ORM框架帮我们做到了这一点（查询单条的操作都会自动加上limit 1）
  
# 慢查询日志
  用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考
  
  - 开启慢查询日志
  - 设置临界时间
  - 查看日志
  - profile信息
    - 开启profile信息
    - 查看profile信息
    - 通过Query_ID查看某条SQL所有详细步骤的时间

# 典型的服务器配置

  - max_connections，最大客户端连接数
  - table_open_cache，表文件句柄缓存（表数据是存储在磁盘上的，缓存磁盘文件的句柄方便打开文件读取数据）
  - key_buffer_size，索引缓存大小（将从磁盘上读取的索引缓存到内存，可以设置大一些，有利于快速检索）
  - innodb_buffer_pool_size，Innodb存储引擎缓存池大小（对于Innodb来说最重要的一个配置，如果所有的表用的都是Innodb，那么甚至建议将该值设置到物理内存的80%，Innodb的很多性能提升如索引都是依靠这个）
  - innodb_file_per_table（innodb中，表数据存放在.ibd文件中，如果将该配置项设置为ON，那么一个表对应一个ibd文件，否则所有innodb共享表空间）
  
# 压测工具mysqlslap

  - 自动生成sql测试
  - 并发测试
  - 多轮测试
  - 存储引擎测试
